{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fyp.twitter_api import twitter_api, convert_datetime_to_ISO_8601, ratelimit_wait\n",
    "from fyp.db import User, UserInteractorRelationships, Database, db\n",
    "import matplotlib.pyplot as plt\n",
    "from fyp.crypto import Crypto\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fyp.secrets import SECRETS\n",
    "headers = {\"Authorization\": f\"Bearer {SECRETS.TWITTER_BEARER_TOKEN}\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, name):\n",
    "    base = \"/its/home/ep396/Documents/FYP/data/snowball_second/\"\n",
    "    e = base + f\"encrypted_{name}.json\"\n",
    "    d = base + f\"decrypted_{name}.json\"\n",
    "\n",
    "    with open(d, \"w\", encoding=\"utf8\") as outfile:\n",
    "        json.dump(data, outfile, indent=4, ensure_ascii=False)\n",
    "\n",
    "    crypto.age_encrypt_file(d, e)\n",
    "\n",
    "    os.remove(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name):\n",
    "    base = \"/its/home/ep396/Documents/FYP/data/snowball_second/\"\n",
    "    e = base + f\"encrypted_{name}.json\"\n",
    "    d = base + f\"decrypted_{name}.json\"\n",
    "\n",
    "    crypto.age_decrypt_file(e, d)\n",
    "\n",
    "    file = open(d, encoding='utf8')\n",
    "    data = json.load(file)\n",
    "    file.close()\n",
    "\n",
    "    os.remove(d)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_hop = 1\n",
    "crypto = Crypto()\n",
    "database = Database(crypto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get seed users from db\n",
    "users = {\n",
    "    int(crypto.fernet_decrypt(user.twitter_user_id)):user.id\n",
    "    for user in User.select(User.id, User.twitter_user_id).where(User.hop == start_hop)\n",
    "}\n",
    "\n",
    "user_reverse = {value: key for key, value in users.items()}\n",
    "user_twitter_ids = [user for user in users.keys()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4852"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_timeframe = (datetime.datetime(2021, 1, 1, 0, 0, 0), datetime.datetime(2021, 12, 31, 23, 59, 59))\n",
    "timeframe = tuple([convert_datetime_to_ISO_8601(timeframe) for timeframe in raw_timeframe])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_seed_user_query = (\n",
    "    '(\"trans\" OR \"enby\" OR \"transgender\" OR \"nonbinary\" OR ' + \n",
    "    '\"genderist\" OR \"genderism\" OR \"gender cult\" OR ' + \n",
    "    '\"adult human female\" OR \"#SexNotGender\" OR ' +\n",
    "    '\"#IStandWithJKRowling\" OR \"#SexMatters\" OR ' +\n",
    "    '\"#BiologyNotBigotry\" OR \"#WarOnWomen\" OR ' +\n",
    "    '\"#IStandWithJKR\" OR \"Gender Critical\" OR ' +\n",
    "    '\"#IStandWithMayaForstater\") REPLACEME -\"eng trans\" '+\n",
    "    '-\"#transporn\" -\"#porn\" -is:nullcast ' +\n",
    "    'lang:en -is:retweet'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_tweets(user_id, base_query):\n",
    "    query = base_query.replace(\"REPLACEME\", f\"from:{user_id}\")\n",
    "    concat_data, next_token, cont = [], None, True\n",
    "    start, end = timeframe\n",
    "\n",
    "    while cont:\n",
    "        params = {\n",
    "            \"query\": query,\n",
    "            \"next_token\": next_token,\n",
    "            \"start_time\": start,\n",
    "            \"end_time\": end,\n",
    "            \"tweet.fields\": \"public_metrics,conversation_id,referenced_tweets,reply_settings,in_reply_to_user_id,created_at\",\n",
    "            \"expansions\": \"author_id\",\n",
    "            \"max_results\": 500,\n",
    "        }\n",
    "\n",
    "        data, limit_remaining_requests, limit_reset_time = twitter_api(\n",
    "            url=\"https://api.twitter.com/2/tweets/search/all\",\n",
    "            headers=headers,\n",
    "            params=params,\n",
    "            data_location=\"data\",\n",
    "        )\n",
    "\n",
    "        if data[\"fyp\"][\"error\"] is True:\n",
    "            if (limit_remaining_requests <= 0 and cont is True) or (\"status\" in data and data[\"status\"] == 429):\n",
    "                ratelimit_wait(limit_reset_time, \"tweets\", len(concat_data))\n",
    "            elif \"meta\" in data and data[\"meta\"][\"result_count\"] == 0:\n",
    "                cont = False\n",
    "            else:\n",
    "                raise Exception(data)\n",
    "        else:\n",
    "            concat_data += data[\"data\"]\n",
    "            print(f\"Added: {len(data['data'])}\")\n",
    "            print(f\"Total: {len(concat_data)}\\n\")\n",
    "            next_token = (\n",
    "                data[\"meta\"][\"next_token\"]\n",
    "                if \"next_token\" in data[\"meta\"]\n",
    "                else None\n",
    "            )\n",
    "\n",
    "            if next_token is None and data[\"fyp\"][\"error\"] is False:\n",
    "                cont = False\n",
    "\n",
    "            time.sleep(1.05)\n",
    "\n",
    "    return concat_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through seed users, get relevant tweet IDs of a timespan of a year\n",
    "for user_twitter_id, user_db_id in tqdm(users.items()):\n",
    "    print(f\"==> User {user_db_id}\")\n",
    "    tweets[user_twitter_id] = get_user_tweets(user_twitter_id, base_seed_user_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(tweets, \"tweets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = load_data(\"tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversation_tweets(user_id, tweet_conversation_id):\n",
    "    query = f\"conversation_id:{tweet_conversation_id} -is:retweet lang:en\"\n",
    "    concat_data, next_token, cont = [], None, True\n",
    "    start, end = timeframe\n",
    "\n",
    "    while cont:\n",
    "        params = {\n",
    "            \"query\": query,\n",
    "            \"next_token\": next_token,\n",
    "            \"start_time\": start,\n",
    "            \"end_time\": end,\n",
    "            \"expansions\": \"author_id\",\n",
    "            \"max_results\": 500,\n",
    "        }\n",
    "\n",
    "        data, limit_remaining_requests, limit_reset_time = twitter_api(\n",
    "            url=\"https://api.twitter.com/2/tweets/search/all\",\n",
    "            headers=headers,\n",
    "            params=params,\n",
    "            data_location=\"data\",\n",
    "        )\n",
    "\n",
    "        if data[\"fyp\"][\"error\"] is True:\n",
    "            if (limit_remaining_requests <= 0 and cont is True) or (\"status\" in data and data[\"status\"] == 429):\n",
    "                ratelimit_wait(limit_reset_time, \"tweets\", len(concat_data))\n",
    "            elif \"meta\" in data and data[\"meta\"][\"result_count\"] == 0:\n",
    "                cont = False\n",
    "                print(\"None\")\n",
    "            else:\n",
    "                raise Exception(data)\n",
    "        else:\n",
    "            concat_data += data[\"data\"]\n",
    "            print(f\"Added: {len(data['data'])}\")\n",
    "            print(f\"Total: {len(concat_data)}\\n\")\n",
    "            next_token = (\n",
    "                data[\"meta\"][\"next_token\"]\n",
    "                if \"next_token\" in data[\"meta\"]\n",
    "                else None\n",
    "            )\n",
    "\n",
    "            if next_token is None and data[\"fyp\"][\"error\"] is False:\n",
    "                cont = False\n",
    "\n",
    "            time.sleep(1.05)\n",
    "\n",
    "    return concat_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_tweets_naive(user_twitter_ids, tweets, cap):\n",
    "    best_user_tweets = {}\n",
    "    for user in user_twitter_ids:\n",
    "        user_tweets = tweets[str(user)]\n",
    "        user_tweets_sums = []\n",
    "\n",
    "        for tweet in user_tweets:\n",
    "            tweet_metrics = tweet[\"public_metrics\"]\n",
    "            metric_sum = sum([metric for metric in tweet_metrics.values()])\n",
    "            user_tweets_sums.append((tweet['id'], metric_sum, tweet_metrics, tweet[\"conversation_id\"]))\n",
    "        \n",
    "        user_tweets_sums.sort(key=lambda y: y[1], reverse=True)\n",
    "        best_user_tweets[user] = user_tweets_sums[:cap]\n",
    "    \n",
    "    return best_user_tweets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_user_tweets = get_top_tweets_naive(user_twitter_ids, tweets, cap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repliers(top_user_tweets):\n",
    "    __concat_data = {}\n",
    "\n",
    "    for i, pair in enumerate(top_user_tweets.items()):\n",
    "        user, tweets = pair\n",
    "        print(f\"=> User {i}\")\n",
    "        __concat_data[user] = []\n",
    "        for j, tweet in enumerate(tweets):\n",
    "            print(f\"==> Tweet {j}\")\n",
    "            collected_tweets = get_conversation_tweets(user, tweet[-1])\n",
    "            __concat_data[user] += [collected_tweet[\"author_id\"] for collected_tweet in collected_tweets]\n",
    "    \n",
    "    return __concat_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repliers = get_repliers(top_user_tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(repliers, \"repliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_repliers(users, repliers):\n",
    "    unique_users = []\n",
    "    relations = {}\n",
    "\n",
    "    for user in users:\n",
    "        captured_users = repliers[user]\n",
    "        relations[user] = []\n",
    "        for captured_user in captured_users:\n",
    "            if captured_user not in unique_users: unique_users.append(captured_user)\n",
    "            if captured_user not in relations[user]: relations[user].append(captured_user)\n",
    "\n",
    "    return unique_users, relations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_repliers, unique_repliers_interactors = get_unique_repliers(user_twitter_ids, repliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(unique_repliers, \"unique_repliers\")\n",
    "save_data(unique_repliers_interactors, \"unique_repliers_relations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_repliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([len(relation) for relation in unique_repliers_interactors.values()])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6ade73bf49f1256608149ff920ccd937fcccdc8efd4975ff38aa98fc4d821ac5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('fyp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
