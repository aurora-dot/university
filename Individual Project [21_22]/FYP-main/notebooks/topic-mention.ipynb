{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import datetime  \n",
    "\n",
    "from fyp.crypto import Crypto\n",
    "from fyp.influence_measures import ri, snp\n",
    "from fyp.twitter_api import twitter_api, convert_datetime_to_ISO_8601\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fyp.secrets import SECRETS\n",
    "headers = {\"Authorization\": f\"Bearer {SECRETS.TWITTER_BEARER_TOKEN}\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRYPTO = Crypto()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = '/its/home/ep396/Documents/FYP/data/decrypted-new-initial-tweets.json'\n",
    "e = '/its/home/ep396/Documents/FYP/data/encrypted-new-initial-tweets.json'\n",
    "\n",
    "CRYPTO.age_decrypt_file(e, d)\n",
    "\n",
    "file = open(d, encoding='utf8')\n",
    "data = json.load(file)\n",
    "file.close()\n",
    "\n",
    "os.remove(d)\n",
    "\n",
    "len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class janky_metrics():\n",
    "    def get_users_metrics(tweet_data: dict) -> dict:\n",
    "        user_data = {}\n",
    "\n",
    "        for tweet in tweet_data:\n",
    "            author, metrics = tweet[\"author_id\"], tweet[\"public_metrics\"]\n",
    "            metric_list = np.array([metric for metric in metrics.values()])\n",
    "            if author not in user_data:\n",
    "                user_data[author] = metric_list\n",
    "            else:\n",
    "                user_data[author] = np.add(metric_list, user_data[author])\n",
    "\n",
    "        return user_data\n",
    "\n",
    "\n",
    "    def collect_user_totals_metrics(user_data: dict, weights: np.array) -> dict:\n",
    "        totals = {}\n",
    "\n",
    "        for user, metric_array in user_data.items():\n",
    "            totals[user] = np.sum(metric_array * weights)\n",
    "\n",
    "        return totals\n",
    "\n",
    "\n",
    "    def get_x_best_users(user_totals: dict, x: int) -> list:\n",
    "        assert x <= len(user_totals)\n",
    "\n",
    "        best_users = []\n",
    "        sorted_totals = dict(\n",
    "            sorted(user_totals.items(), key=lambda x: x[1], reverse=True)\n",
    "        )\n",
    "\n",
    "        for idx, (k, v) in enumerate(sorted_totals.items()):\n",
    "            if idx == x:\n",
    "                break\n",
    "            best_users.append((int(k), v))\n",
    "\n",
    "        return best_users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = janky_metrics.get_users_metrics(data)\n",
    "total_metrics = janky_metrics.collect_user_totals_metrics(metrics, np.array([1, 1, 1, 1]))\n",
    "best_users = janky_metrics.get_x_best_users(total_metrics, 50) # CHANGE IN PROD\n",
    "print(len(total_metrics))\n",
    "print(len(best_users))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def user_id_to_usernames(best_users):\n",
    "    groupings = np.array_split([user[0] for user in best_users], 5)\n",
    "    url = \"https://api.twitter.com/2/users\"\n",
    "    users = []\n",
    "\n",
    "    for i in range(5):\n",
    "        ids_str = \"\"\n",
    "        for id in groupings[i]:\n",
    "            ids_str += f\"{id},\"\n",
    "        ids_str = ids_str[:-1]\n",
    "\n",
    "        params = {\n",
    "            \"ids\": ids_str,\n",
    "            \"user.fields\": \"username\"\n",
    "        }\n",
    "\n",
    "        (\n",
    "            user_data,\n",
    "            limit_remaining_requests,\n",
    "            limit_reset_time\n",
    "        ) = twitter_api(headers=headers, url=url, params=params, data_location='data')\n",
    "\n",
    "        if user_data[\"fyp\"][\"error\"] == True:\n",
    "            raise Exception(user_data)\n",
    "\n",
    "        users += user_data[\"data\"]\n",
    "        time.sleep(1.05)\n",
    "    \n",
    "    return {int(user[\"id\"]):user[\"username\"] for user in users}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratelimit_wait(limit_reset_time, thing, len_concat_data):\n",
    "    print(\"---- Start Ratelimit Wait ----\")\n",
    "    print(f\"Current {thing} captured: {len_concat_data}\")\n",
    "    print(f\"Unix epochs when: {limit_reset_time}\")\n",
    "    time_reset = datetime.datetime.fromtimestamp(limit_reset_time)\n",
    "    print(f\"Completion when: {time_reset}\")\n",
    "    time.sleep(time.mktime(time_reset.timetuple()) - time.time() + 1)\n",
    "    print(f\"Completed, time is: {datetime.datetime.now()}\")\n",
    "    print(\"---- End Ratelimit Wait ----\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_user_tweet_discourse_count(user_id_name_pair):\n",
    "    url = \"https://api.twitter.com/2/tweets/counts/all\"\n",
    "    data_stuff = {}\n",
    "\n",
    "    for idx, pair in enumerate(user_id_name_pair.items()):\n",
    "        user_id, user_username = pair\n",
    "        params = {\n",
    "            \"query\": f'(\"trans\" OR \"enby\" OR \"transgender\" OR \"nonbinary\") -\"eng trans\" -\"#transporn\" -\"#porn\" -is:nullcast lang:en -is:retweet is:reply from:{user_username}',\n",
    "            \"start_time\": convert_datetime_to_ISO_8601(datetime.datetime(2021, 1, 1, 1, 0, 0, 0)),\n",
    "            \"end_time\": convert_datetime_to_ISO_8601(datetime.datetime(2021, 12, 31, 23, 59, 59, 999999)),\n",
    "            \"granularity\": \"day\"\n",
    "        }\n",
    "\n",
    "        print(f\"=> User {idx}\")\n",
    "\n",
    "        cont, concat_data = True, []\n",
    "\n",
    "        while cont:\n",
    "            (\n",
    "                api_data, \n",
    "                limit_remaining_requests, \n",
    "                limit_reset_time\n",
    "            ) = twitter_api(headers=headers, url=url, params=params, data_location='data')\n",
    "\n",
    "            if api_data['fyp']['error']:\n",
    "                if \"status\" in api_data and api_data[\"status\"] == 429:\n",
    "                    ratelimit_wait(limit_reset_time, 'mentions', len(concat_data))\n",
    "                else:\n",
    "                    raise Exception(api_data)\n",
    "            else:\n",
    "                if api_data[\"fyp\"][\"error\"] is False:\n",
    "                    concat_data += api_data[\"data\"]\n",
    "                    print(f\"Added: {len(api_data['data'])}\")\n",
    "                    print(f\"Total: {len(concat_data)}\\n\")\n",
    "                    params[\"next_token\"] = api_data[\"meta\"][\"next_token\"] if \"next_token\" in api_data[\"meta\"] else None\n",
    "\n",
    "                if params[\"next_token\"] is None and api_data[\"fyp\"][\"error\"] is False:\n",
    "                    cont = False\n",
    "\n",
    "                if limit_remaining_requests <= 0 and cont is True:\n",
    "                    ratelimit_wait(limit_reset_time, 'mentions', len(concat_data))\n",
    "\n",
    "            time.sleep(0.25)\n",
    "\n",
    "        data_stuff[user_id] = concat_data\n",
    "    \n",
    "    return data_stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tweet_discourse_count(data_stuff):\n",
    "    user_count_totals = {}\n",
    "\n",
    "    for user in best_users:\n",
    "        user_id = user[0]\n",
    "        counts = data_stuff[user_id]\n",
    "        total = 0\n",
    "        for count in counts:\n",
    "            total += count[\"tweet_count\"]\n",
    "        user_count_totals[user_id] = total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_discourse_users = janky_metrics.get_x_best_users(user_count_totals, 15)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6ade73bf49f1256608149ff920ccd937fcccdc8efd4975ff38aa98fc4d821ac5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('fyp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
